{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SimpleETL.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oX0H2cfVA003",
        "outputId": "7e495c0a-a34e-4573-9809-e23e3366b6a8"
      },
      "source": [
        "import glob\n",
        "file_csv = glob.glob('./sample_data/*.json')\n",
        "for x in file_csv:\n",
        "  print(x)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "./sample_data/anscombe.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NYPWt0e0LFlH"
      },
      "source": [
        "# Simple ETL - IBM Course Guided"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pxa4SJ3xODsK"
      },
      "source": [
        "## Import modules\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mUUU8Yd9OF5f"
      },
      "source": [
        "import glob                         # this module helps in selecting files \n",
        "import pandas as pd                 # this module helps in processing CSV files\n",
        "import xml.etree.ElementTree as ET  # this module helps in processing XML files.\n",
        "from datetime import datetime"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3vEhbEQkLS5T"
      },
      "source": [
        "## Download"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PwrHLFuKOHc_",
        "outputId": "3b1ebc90-bbde-48c5-af55-c9b1f5efda96"
      },
      "source": [
        "!wget https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-PY0221EN-SkillsNetwork/labs/module%206/Lab%20-%20Extract%20Transform%20Load/data/datasource.zip"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-05-21 13:58:46--  https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-PY0221EN-SkillsNetwork/labs/module%206/Lab%20-%20Extract%20Transform%20Load/data/datasource.zip\n",
            "Resolving cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud (cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud)... 169.45.118.108\n",
            "Connecting to cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud (cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud)|169.45.118.108|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4249 (4.1K) [application/zip]\n",
            "Saving to: ‘datasource.zip’\n",
            "\n",
            "datasource.zip      100%[===================>]   4.15K  --.-KB/s    in 0s      \n",
            "\n",
            "2021-05-21 13:58:47 (374 MB/s) - ‘datasource.zip’ saved [4249/4249]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8uGIYxtxOMHZ",
        "outputId": "52133187-0b02-459a-d4a3-a5f93b2ebc26"
      },
      "source": [
        "!unzip datasource.zip -d dealership_data"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  datasource.zip\n",
            "  inflating: dealership_data/used_car_prices1.csv  \n",
            "  inflating: dealership_data/used_car_prices2.csv  \n",
            "  inflating: dealership_data/used_car_prices3.csv  \n",
            "  inflating: dealership_data/used_car_prices1.json  \n",
            "  inflating: dealership_data/used_car_prices2.json  \n",
            "  inflating: dealership_data/used_car_prices3.json  \n",
            "  inflating: dealership_data/used_car_prices1.xml  \n",
            "  inflating: dealership_data/used_car_prices2.xml  \n",
            "  inflating: dealership_data/used_car_prices3.xml  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qnjsrcetLbul"
      },
      "source": [
        "## Set Path\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i7wbY0IjOQIq"
      },
      "source": [
        "tmpfile    = \"dealership_temp.tmp\"               # file used to store all extracted data\n",
        "logfile    = \"dealership_logfile.txt\"            # all event logs will be stored in this file\n",
        "targetfile = \"dealership_transformed_data.csv\"   # file where transformed data is stored"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GOULb16WLb2N"
      },
      "source": [
        "## Extract"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wJUvJsatOWA_"
      },
      "source": [
        "def extract_from_csv(file_to_process):\n",
        "    dataframe = pd.read_csv(file_to_process)\n",
        "    return dataframe"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PKx5BrArOWXp"
      },
      "source": [
        "def extract_from_json(file_to_process):\n",
        "    dataframe = pd.read_json(file_to_process,lines=True)\n",
        "    return dataframe"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RVTYxcU5OWk9"
      },
      "source": [
        "def extract_from_xml(file_to_process): #car_model, year_of_manufacture, price, and fuel.\n",
        "    dataframe = pd.DataFrame(columns=[\"car_model\", \"year_of_manufacture\", \"price\", \"fuel\"])\n",
        "    tree = ET.parse(file_to_process)\n",
        "    root = tree.getroot()\n",
        "    for row in root:\n",
        "        model = row.find(\"car_model\").text\n",
        "        year_of_manufacture = int(row.find(\"year_of_manufacture\").text)\n",
        "        price = float(row.find(\"price\").text)\n",
        "        fuel = row.find(\"fuel\").text\n",
        "        dataframe = dataframe.append({\"car_model\": model, \"year_of_manufacture\": year_of_manufacture, \"price\":price, \"fuel\":fuel}, ignore_index=True)\n",
        "    return dataframe"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "orbm-WPMPaRn"
      },
      "source": [
        "def extract():\n",
        "    extracted_data = pd.DataFrame(columns=['car_model','year_of_manufacture','price', 'fuel']) # create an empty data frame to hold extracted data\n",
        "    \n",
        "    #process all csv files\n",
        "    for csvfile in glob.glob(\"./dealership_data/*.csv\"):\n",
        "        extracted_data = extracted_data.append(extract_from_csv(csvfile), ignore_index=True)\n",
        "        \n",
        "    #process all json files\n",
        "    for jsonfile in glob.glob(\"./dealership_data/*.json\"):\n",
        "        extracted_data = extracted_data.append(extract_from_json(jsonfile), ignore_index=True)\n",
        "    \n",
        "    #process all xml files\n",
        "    for xmlfile in glob.glob(\"./dealership_data/*.xml\"):\n",
        "        extracted_data = extracted_data.append(extract_from_xml(xmlfile), ignore_index=True)\n",
        "        \n",
        "    return extracted_data"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LgD4dInXLcHV"
      },
      "source": [
        "## Transform"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NlJA_HinPnuZ"
      },
      "source": [
        "def transform(data):\n",
        "  data['price'] = data['price'].round(2)\n",
        "  return data"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8wUVkXFdPMj6"
      },
      "source": [
        "## Load"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "04TbSEGWPwzl"
      },
      "source": [
        "def load(targetfile, data):\n",
        "  data.to_csv(targetfile)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uETf64omPMtB"
      },
      "source": [
        "## Log"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jrWYuPeNPT0j"
      },
      "source": [
        "def log(message):\n",
        "    timestamp_format = '%Y-%h-%d-%H:%M:%S' # Year-Monthname-Day-Hour-Minute-Second\n",
        "    now = datetime.now() # get current timestamp\n",
        "    timestamp = now.strftime(timestamp_format)\n",
        "    with open(\"./dealership_data/logfile.txt\",\"a\") as f:\n",
        "        f.write(timestamp + ',' + message + '\\n')"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j8Hwo1VCQA7j"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TIC8kAwrQBgA"
      },
      "source": [
        "## Run"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lsm1UjNrQC4j"
      },
      "source": [
        "log(\"ETL Job Started\")\n",
        "log(\"Extract phase Started\")\n",
        "extracted_data = extract()\n",
        "log(\"Extract phase Ended\")\n",
        "\n",
        "log(\"Transform phase Started\")\n",
        "transformed_data = transform(extracted_data)\n",
        "log(\"Transform phase Ended\")\n",
        "\n",
        "log(\"Load phase Started\")\n",
        "load(targetfile,transformed_data)\n",
        "log(\"Load phase Ended\")\n",
        "log(\"ETL Job Ended\")"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nwzn9vWuQirp"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}